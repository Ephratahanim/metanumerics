using System;
using System.Collections.Generic;
using System.Diagnostics;

using Meta.Numerics.Analysis;
using Meta.Numerics.Matrices;

namespace Meta.Numerics.Statistics {
    public static class Bivariate {

        private static void ComputeBivariateMomentsUpToTwo (IEnumerable<double> x, IEnumerable<double> y, out int n, out double xMean, out double yMean, out double xxSum, out double yySum, out double xySum) {

            Debug.Assert(x != null);
            Debug.Assert(y != null);

            IEnumerator<double> xEnumerator = x.GetEnumerator();
            IEnumerator<double> yEnumerator = y.GetEnumerator();

            n = 0;
            xMean = 0.0;
            yMean = 0.0;
            xxSum = 0.0;
            yySum = 0.0;
            xySum = 0.0;

            while (true) {

                bool xFlag = xEnumerator.MoveNext();
                bool yFlag = yEnumerator.MoveNext();
                if (!xFlag) {
                    Debug.Assert(!yFlag);
                    break;
                }

                n++;
                double e = 1.0 / n;

                double xValue = xEnumerator.Current;
                double xDelta = xValue - xMean;
                xMean += xDelta * e;

                double yValue = yEnumerator.Current;
                double yDelta = yValue - yMean;
                yMean += yDelta * e;

                e = 1.0 - e;

                xxSum += xDelta * xDelta * e;
                yySum += yDelta * yDelta * e;
                xySum += xDelta * yDelta * e;

            }

        }


        public static double Covariance (IReadOnlyCollection<double> x, IReadOnlyCollection<double> y) {

            if (x == null) throw new ArgumentNullException(nameof(x));
            if (y == null) throw new ArgumentNullException(nameof(y));
            if (x.Count != y.Count) throw new DimensionMismatchException();

            int n;
            double xMean, yMean, xxSum, yySum, xySum;
            ComputeBivariateMomentsUpToTwo(x, y, out n, out xMean, out yMean, out xxSum, out yySum, out xySum);

            return (xySum / n);
        }

        public static double CorrelationCoefficient (IReadOnlyCollection<double> x, IReadOnlyCollection<double> y) {

            if (x == null) throw new ArgumentNullException(nameof(x));
            if (y == null) throw new ArgumentNullException(nameof(y));
            if (x.Count != y.Count) throw new DimensionMismatchException();

            int n;
            double xMean, yMean, xxSum, yySum, xySum;
            ComputeBivariateMomentsUpToTwo(x, y, out n, out xMean, out yMean, out xxSum, out yySum, out xySum);

            Debug.Assert(xxSum >= 0.0);
            Debug.Assert(yySum >= 0.0);

            return (xySum / Math.Sqrt(xxSum * yySum));

        }

        /// <summary>
        /// Computes the best-fit linear regression from the data.
        /// </summary>
        /// <returns>The result of the fit.</returns>
        /// <remarks>
        /// <para>Linear regression assumes that the data have been generated by a function y = a + b x + e, where e is
        /// normally distributed noise, and determines the values of a and b that best fit the data. It also
        /// determines a covariance matrix on the parameters a and b, and computes an ANOVA analysis of the fit.</para>
        /// </remarks>
        /// <exception cref="InsufficientDataException">There are fewer than three data points.</exception>
        public static LinearRegressionResult LinearRegression(IReadOnlyList<double> x, IReadOnlyList<double> y) {

            if (x == null) throw new ArgumentNullException(nameof(x));
            if (y == null) throw new ArgumentNullException(nameof(y));
            if (x.Count != y.Count) throw new DimensionMismatchException();

            int n;
            double xMean, yMean, xxSum, yySum, xySum;
            ComputeBivariateMomentsUpToTwo(x, y, out n, out xMean, out yMean, out xxSum, out yySum, out xySum);

            if (n < 3) throw new InsufficientDataException();

            // Compute the best-fit parameters
            double b = xySum / xxSum;
            double a = yMean - b * xMean;
            // Since cov(x,y) = (n S_xy - S_x S_y)/n^2 and var(x) = (n S_xx - S_x^2) / n^2,
            // these formulas are equivilent to the 
            // to the usual formulas for a and b involving sums, but it is more stable against round-off
            ColumnVector v = new ColumnVector(a, b);
            v.IsReadOnly = true;

            // Compute Pearson r value
            double r = xySum / Math.Sqrt(xxSum * yySum);
            TestResult rTest = new TestResult("r", r, TestType.TwoTailed, new Distributions.PearsonRDistribution(n));

            // Compute residuals and other sum-of-squares
            double SSR = 0.0;
            double SSF = 0.0;
            Sample residuals = new Sample();
            IEnumerator<double> xEnumerator = x.GetEnumerator();
            IEnumerator<double> yEnumerator = y.GetEnumerator();
            while(true) {
                bool xFlag = xEnumerator.MoveNext();
                bool yFlag = yEnumerator.MoveNext();
                if (!xFlag) {
                    Debug.Assert(!yFlag);
                    break;
                }
                double xValue = xEnumerator.Current;
                double yPredicted = a + b * xValue;
                double yValue = yEnumerator.Current;
                double z = yValue - yPredicted;
                SSR += MoreMath.Sqr(z);
                SSF += MoreMath.Sqr(yPredicted - yMean);
                residuals.Add(z);
            }
            double SST = yySum;
            // Note SST = SSF + SSR because \sum_{i} ( y_i - \bar{y})^2 = \sum_i (y_i - f_i)^2 + \sum_i (f_i - \bar{y})^2

            // Use sums-of-squares to do ANOVA
            AnovaRow fit = new AnovaRow(SSF, 1);
            AnovaRow residual = new AnovaRow(SSR, n - 2);
            AnovaRow total = new AnovaRow(SST, n - 1);
            OneWayAnovaResult anova = new OneWayAnovaResult(fit, residual, total);

            // Compute covariance of parameters matrix
            double xVar = xxSum / n;
            double s2 = SSR / (n - 2);
            double cbb = s2 / xVar / n;
            double cab = -xMean * cbb;
            double caa = (xVar + xMean * xMean) * cbb;

            SymmetricMatrix C = new SymmetricMatrix(2);
            C[0, 0] = caa;
            C[1, 1] = cbb;
            C[0, 1] = cab;
            C.IsReadOnly = true;

            // Package the parameters
            ParameterCollection parameters = new ParameterCollection(
                new string[] { "Intercept", "Slope" }, v, C
            );

            // Prepare the prediction function
            Func<double, UncertainValue> predict = (double xValue) => {
                double yPredicted = a + b * xValue;
                return (new UncertainValue(yPredicted, Math.Sqrt(s2 * (1.0 + (1.0 + MoreMath.Sqr(xValue - xMean) / xVar) / n))));
            };

            return (new LinearRegressionResult(parameters, rTest, anova, residuals, predict));

        }

        public static PolynomialRegressionResult PolynomialRegression (IReadOnlyList<double> x, IReadOnlyList<double> y, int m) {

            if (x == null) throw new ArgumentNullException(nameof(x));
            if (y == null) throw new ArgumentNullException(nameof(y));
            if (x.Count != y.Count) throw new DimensionMismatchException();
            if (m < 0) throw new ArgumentOutOfRangeException(nameof(m));

            int n = x.Count;
            if (n < (m + 1)) throw new InsufficientDataException();

            // Construct the n X m design matrix X_{ij} = x_{i}^{j}
            RectangularMatrix X = new RectangularMatrix(n, m + 1);
            ColumnVector Y = new ColumnVector(n);
            for (int i = 0; i < n; i++) {
                double x_i = x[i];
                X[i, 0] = 1.0;
                for (int j = 1; j <= m; j++) {
                    X[i, j] = X[i, j - 1] * x_i;
                }
                double y_i = y[i];
                Y[i] = y_i;
            }

            // Use X = QR to solve X b = y and compute C
            ColumnVector b;
            SymmetricMatrix C;
            QRDecomposition.SolveLinearSystem(X, Y, out b, out C);

            // Compute mean and total sum of squares.
            // This could be done inside loop above, but this way we get to re-use code from Univariate.
            double yMean, SST;
            Univariate.ComputeMomentsUpToSecond(y, out yMean, out SST);

            // Compute residuals
            double SSR = 0.0;
            double SSF = 0.0;
            ColumnVector yHat = X * b;
            Sample residuals = new Sample();
            for (int i = 0; i < n; i++) {
                double z = y[i] - yHat[i];
                residuals.Add(z);
                SSR += z * z;
                SSF += MoreMath.Sqr(yHat[i] - yMean);
            }
            double sigma2 = SSR / (n - (m + 1));

            // Scale up C by \sigma^2
            // (It sure would be great to be able to overload *=.)
            for (int i = 0; i <= m; i++) {
                for (int j = i; j <= m; j++) {
                    C[i, j] = C[i, j] * sigma2;
                }
            }

            // Use sums-of-squares to do ANOVA
            AnovaRow fit = new AnovaRow(SSF, m);
            AnovaRow residual = new AnovaRow(SSR, n - (m + 1));
            AnovaRow total = new AnovaRow(SST, n - 1);
            OneWayAnovaResult anova = new OneWayAnovaResult(fit, residual, total);

            string[] names = new string[m + 1];
            names[0] = "[1]";
            if (m > 0) names[1] = "[x]";
            for (int i = 2; i <= m; i++) names[i] = $"[x^{i}]";
            ParameterCollection parameters = new ParameterCollection(names, b, C);

            return (new PolynomialRegressionResult(parameters, anova, residuals));
        }

        /// <summary>
        /// Finds the parameterized function that best fits the data.
        /// </summary>
        /// <param name="x">The ordinate values.</param>
        /// <param name="y">The abcissa values.</param>
        /// <param name="f">The parameterized function.</param>
        /// <param name="start">An initial guess for the parameters.</param>
        /// <returns>The fit result.</returns>
        /// <remarks>
        /// <para>
        /// In the returned <see cref="FitResult"/>, the parameters appear in the same order as in
        /// the supplied fit function and initial guess vector. No goodness-of-fit test is returned.
        /// </para>
        /// </remarks>
        /// <exception cref="ArgumentNullException"><paramref name="f"/> or <paramref name="start"/> is null.</exception>
        /// <exception cref="InsufficientDataException">There are not more data points than fit parameters.</exception>
        /// <exception cref="DivideByZeroException">The curvature matrix is singular, indicating that the data is independent of
        /// one or more parameters, or that two or more parameters are linearly dependent.</exception>
        public static RegressionResult NonlinearRegression (IReadOnlyList<double> x, IReadOnlyList<double> y, Func<IList<double>, double, double> f, IReadOnlyList<double> start) {

            if (x == null) throw new ArgumentNullException(nameof(x));
            if (y == null) throw new ArgumentNullException(nameof(y));
            if (f == null) throw new ArgumentNullException(nameof(f));
            if (start == null) throw new ArgumentNullException(nameof(start));
            if (x.Count != y.Count) throw new DimensionMismatchException();

            int n = x.Count;
            int d = start.Count;
            if (n <= d) throw new InsufficientDataException();

            MultiExtremum min = MultiFunctionMath.FindLocalMinimum((IList<double> a) => {
                double ss = 0.0;
                for (int i = 0; i < n; i++) {
                    double r = y[i] - f(a, x[i]);
                    ss += r * r;
                }
                return (ss);
            }, start);

            CholeskyDecomposition cholesky = min.HessianMatrix.CholeskyDecomposition();
            if (cholesky == null) throw new DivideByZeroException();
            SymmetricMatrix curvature = cholesky.Inverse();
            curvature = (2.0 * min.Value / (n - d)) * curvature;

            string[] names = new string[d];
            for (int i = 0; i < names.Length; i++) names[i] = $"Parameter{i}";
            ParameterCollection parameters = new ParameterCollection(names, min.Location, curvature);

            Sample residuals = new Sample();
            for (int i = 0; i < n; i++) {
                double r = y[i] - f(min.Location, x[i]);
                residuals.Add(r);
            }

            RegressionResult result = new RegressionResult(parameters, residuals);

            return (result);
        }

    }
}
